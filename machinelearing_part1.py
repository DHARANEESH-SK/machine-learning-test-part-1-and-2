# -*- coding: utf-8 -*-
"""machinelearing part1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mAhnh2RNn6mgpLut89b0l99-OrkkbSpR
"""

import pandas as pd

from google.colab import drive
drive.mount("/content/drive")

data=pd.read_csv('/content/drive/MyDrive/bank.csv',delimiter=";")

data

"""**Q1. What does the primary analysis of several categorical
features reveal?**

Administrative staff and technical specialists opened the deposit most of all. In relative terms, a high proportion of pensioners and students might be mentioned as well.       
Although in absolute terms married consumers more often agreed to the service, in relative terms the single was responded better.    
Best communication channel is secullar.        
The difference is evident between consumers who already use the services of banks and received a loan.       
Home ownership does not greatly affect marketing company performance.

**Q2. Perform the following Exploratory Data Analysis tasks:**

a. Missing Value Analysis
"""

data.dropna()

"""b. Label Encoding wherever required"""

from sklearn.preprocessing import LabelEncoder
A = LabelEncoder()
data["job"] = A.fit_transform(data["job"])
data

"""c. Selecting important features based on Random Forest

d. Handling unbalanced data using SMOTE
"""

from sklearn.datasets import make_classification
from collections import Counter
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE
from matplotlib import pyplot
from numpy import where
x, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,
	n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)

from collections import Counter
counter = Counter(y)
print(counter)

oversample = SMOTE()
x, y = oversample.fit_resample(x, y)

counter = Counter(y)
print(counter)

for label, _ in counter.items():
	row_ix = where(y == label)[0]
	pyplot.scatter(x[row_ix, 0], x[row_ix, 1], label=str(label))
pyplot.legend()
pyplot.show()

"""**Q3. Build the following Supervised Learning models:**

a. Logistic Regression
"""

from sklearn.linear_model import LogisticRegression

h=LogisticRegression()

from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score

x1=data.drop(['y'],axis=1).values
y1=data['y'].values

from sklearn.preprocessing import LabelEncoder
l = LabelEncoder()
#assigning numeric value 
data['y'] = l.fit_transform(data['y'])
data

data1=pd.get_dummies(data)

x=data1.drop(['y'],axis=1).values
y=data1['y'].values

from sklearn.model_selection import train_test_split

xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=.20,random_state=0)

from sklearn.linear_model import LogisticRegression

i=LogisticRegression()

i.fit(xtrain,ytrain)

p=i.predict(xtest)
i.predict_proba(xtest)

from sklearn.metrics import accuracy_score,classification_report,confusion_matrix

accuracy_score(ytest,p)

confusion_matrix(ytest,p)

s=classification_report(ytest,p)

print(s)

"""b. AdaBoost"""

from sklearn.preprocessing import MinMaxScaler
scaler= MinMaxScaler()
scaler.fit_transform(x)

from sklearn.ensemble import BaggingClassifier
from sklearn import tree
model1 = BaggingClassifier(tree.DecisionTreeClassifier(random_state=10))

"""c. Na√Øve Bayes"""

from sklearn.naive_bayes import GaussianNB

import matplotlib.pyplot as plt
from sklearn.metrics import roc_auc_score,auc
from sklearn.metrics import roc_curve

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.15,random_state=0)

c=GaussianNB()
c.fit(x_train,y_train)

p=c.predict(x_test)

accuracy_score(y_test,p)

naive=classification_report(y_test,p)
print(naive)

"""d. KNN

"""

from sklearn.neighbors import KNeighborsClassifier

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.25,random_state=0)

from sklearn.preprocessing import StandardScaler

sc=StandardScaler()

model4=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)
model4.fit(x_train,y_train)

t=model4.predict(x_test)

model4.predict_proba(x_test)

accuracy_score(y_test,t)

knn=classification_report(y_test,t)
print(knn)

"""e. SVM

"""

from sklearn.svm import SVC

k=SVC(probability=True)

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.20,random_state=0)

k.fit(x_train,y_train)

i=k.predict(x_test)

accuracy_score(y_test,i)

confusion_matrix(y_test,i)

svm=classification_report(y_test,i)
print(svm)

